# Example environment file for local development
# Copy to .env and replace placeholders with your own values.
# DO NOT commit real secrets to version control.

# LLM providers
OPENAI_API_KEY=__REPLACE_WITH_YOUR_KEY__
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# Optional local model host (e.g., Ollama or on-prem deployment)
# Set OPNXT_MODEL_PROVIDER=local to force the router to use this block.
LOCAL_BASE_URL=http://127.0.0.1:11434
LOCAL_MODEL=gpt-oss:120b
# LOCAL_API_KEY= # only if your local server enforces auth

# Force a specific provider (local, openai, gemini, xai)
OPNXT_MODEL_PROVIDER=

# Auth / JWT (dev defaults exist; prefer to set your own)
JWT_SECRET=change-me-in-dev
JWT_EXPIRES_MIN=60

# Public mode (true allows anonymous guest contributor for MVP/demo). For tests/CI set to false.
OPNXT_PUBLIC_MODE=false

# Optional: toggle CI behavior
CI=
GITHUB_ACTIONS=
